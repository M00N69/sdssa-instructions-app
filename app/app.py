import streamlit as st
import pandas as pd
import sqlite3
import os
import requests
from bs4 import BeautifulSoup
from whoosh.index import create_in, exists_in, open_dir, LockError
from whoosh.fields import Schema, TEXT, ID
from whoosh.qparser import QueryParser
from whoosh.analysis import StemmingAnalyzer, LowercaseFilter, StopFilter
import nltk
from nltk.corpus import wordnet
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from datetime import datetime, timedelta
import time
import traceback
import subprocess
import hashlib
import glob
import shutil
from PIL import Image
from io import BytesIO
import base64  # Ajout de l'import pour encodage base64

# Configuration de la page Streamlit avec plus d'options
st.set_page_config(
    page_title="SDSSA Instructions - Visualisation et Recherche",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- Styles CSS personnalis√©s ---
st.markdown(
    """
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1E3A8A;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.8rem;
        font-weight: 600;
        color: #2563EB;
        margin-top: 1.5rem;
        margin-bottom: 1rem;
    }
    .card {
        background-color: #F9FAFB;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        margin-bottom: 20px;
    }
    .highlight-text {
        background-color: #DBEAFE;
        padding: 2px 5px;
        border-radius: 3px;
    }
    .success-message {
        background-color: #D1FAE5;
        color: #065F46;
        padding: 10px;
        border-radius: 5px;
        font-weight: 500;
    }
    .warning-message {
        background-color: #FEF3C7;
        color: #92400E;
        padding: 10px;
        border-radius: 5px;
        font-weight: 500;
    }
    .error-message {
        background-color: #FEE2E2;
        color: #B91C1C;
        padding: 10px;
        border-radius: 5px;
        font-weight: 500;
    }
    .info-box {
        border-left: 4px solid #3B82F6;
        padding: 10px 15px;
        background-color: #EFF6FF;
        margin: 10px 0;
    }
    .stButton button {
        width: 100%;
        border-radius: 5px;
        height: 3em;
        font-weight: 500;
    }
    .stSelectbox div[data-baseweb="select"] {
        border-radius: 5px;
    }
    .status-badge {
        padding: 3px 10px;
        border-radius: 12px;
        font-size: 0.8rem;
        font-weight: 500;
    }
    .badge-success {
        background-color: #D1FAE5;
        color: #065F46;
    }
    .badge-warning {
        background-color: #FEF3C7;
        color: #92400E;
    }
    .tab-content {
        padding: 15px;
        border: 1px solid #E5E7EB;
        border-radius: 0 0 5px 5px;
        margin-top: -5px;
    }
    /* Footer style */
    .footer {
        text-align: center;
        margin-top: 50px;
        padding: 20px;
        border-top: 1px solid #E5E7EB;
        color: #6B7280;
    }
    /* Tableaux plus modernes */
    .dataframe-modern {
        border-collapse: collapse;
        width: 100%;
        border-radius: 8px;
        overflow: hidden;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .dataframe-modern th {
        background-color: #2563EB;
        color: white;
        padding: 12px;
        text-align: left;
    }
    .dataframe-modern td {
        padding: 10px;
        border-bottom: 1px solid #E5E7EB;
    }
    .dataframe-modern tr:nth-child(even) {
        background-color: #F3F4F6;
    }
    .dataframe-modern tr:hover {
        background-color: #EFF6FF;
    }
</style>
""",
    unsafe_allow_html=True,
)

# --- Initialisation de la session state ---
if "db_last_checked" not in st.session_state:
    st.session_state.db_last_checked = None
if "is_db_updated" not in st.session_state:
    st.session_state.is_db_updated = False
if "search_results" not in st.session_state:
    st.session_state.search_results = None
if "selected_instruction" not in st.session_state:
    st.session_state.selected_instruction = None
if "filter_year" not in st.session_state:
    st.session_state.filter_year = None
if "filter_week" not in st.session_state:
    st.session_state.filter_week = None
if "update_frequency" not in st.session_state:
    st.session_state.update_frequency = "Hebdomadaire"

# --- Initialisation NLTK ---
@st.cache_resource
def initialize_nltk():
    """Initialise les ressources NLTK."""
    try:
        nltk.data.find("tokenizers/punkt")
    except LookupError:
        nltk.download("punkt")

    try:
        nltk.data.find("corpora/wordnet")
    except LookupError:
        nltk.download("wordnet")
        nltk.download("omw-1.4")

initialize_nltk()

# --- Configuration des r√©pertoires ---
os.makedirs("data", exist_ok=True)
os.makedirs("indexdir", exist_ok=True)
os.makedirs("backups", exist_ok=True)

# --- Fonction pour t√©l√©charger la base de donn√©es depuis GitHub ---
def download_db_from_github(force=False):
    """T√©l√©charge la base de donn√©es depuis GitHub si une version plus r√©cente est disponible."""
    # URL directe vers le fichier dans le d√©p√¥t GitHub
    github_raw_url = "https://raw.githubusercontent.com/M00N69/sdssa-instructions-app/main/data/sdssa_instructions.db"
    local_db_path = "data/sdssa_instructions.db"

    # D√©finir les headers avec un User-Agent
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    try:
        # V√©rifier si le fichier existe localement et obtenir sa date de modification
        local_modification_time = None
        local_hash = None
        if os.path.exists(local_db_path):
            local_modification_time = os.path.getmtime(local_db_path)
            local_modification_date = datetime.fromtimestamp(local_modification_time)

            # Calculer le hash de la base locale pour d√©tecter les changements
            with open(local_db_path, "rb") as f:
                local_hash = hashlib.md5(f.read()).hexdigest()

            with st.status(
                f"üìÖ Base de donn√©es locale du {local_modification_date.strftime('%d/%m/%Y √† %H:%M')}"
            ):
                st.write("V√©rification des mises √† jour...")

        # T√©l√©charger directement le fichier sans v√©rifier les en-t√™tes (plus fiable)
        with st.spinner("T√©l√©chargement de la base de donn√©es..."):
            response = requests.get(
                github_raw_url, headers=headers, allow_redirects=True, timeout=30
            )

            if response.status_code == 200:
                # Calculer le hash de la nouvelle version
                new_content = response.content
                new_hash = hashlib.md5(new_content).hexdigest()

                # V√©rifier si le contenu a r√©ellement chang√© ou si le t√©l√©chargement est forc√©
                if force or not local_hash or new_hash != local_hash:
                    # Cr√©er une sauvegarde dat√©e
                    if os.path.exists(local_db_path):
                        backup_date = datetime.now().strftime("%Y%m%d_%H%M%S")
                        backup_path = f"backups/sdssa_instructions_{backup_date}.db"
                        shutil.copy2(local_db_path, backup_path)
                        st.write(f"‚úÖ Sauvegarde cr√©√©e: {backup_path}")

                    # √âcrire la nouvelle version
                    with open(local_db_path, "wb") as f:
                        f.write(new_content)

                    st.success("‚úÖ Base de donn√©es mise √† jour avec succ√®s!")
                    st.session_state.is_db_updated = True

                    # Limiter le nombre de sauvegardes (garder les 5 plus r√©centes)
                    backups = sorted(glob.glob("backups/sdssa_instructions_*.db"))
                    if len(backups) > 5:
                        for old_backup in backups[:-5]:
                            os.remove(old_backup)

                    return True
                else:
                    st.info(
                        "üìå Le contenu de la base de donn√©es est identique - aucune mise √† jour n√©cessaire"
                    )
                    return True
            else:
                st.error(f"‚ùå Erreur lors du t√©l√©chargement: {response.status_code}")
                return False

    except Exception as e:
        st.error(f"‚ùå Erreur lors du t√©l√©chargement de la base de donn√©es: {e}")
        st.error(traceback.format_exc())
        return False

# --- Fonctions de gestion de la base de donn√©es SQLite ---
def get_db_connection():
    """Cr√©e et retourne une connexion √† la base de donn√©es avec un context manager."""
    db_path = "data/sdssa_instructions.db"
    if not os.path.exists(db_path):
        st.error(
            "‚ùå Base de donn√©es non trouv√©e! Veuillez t√©l√©charger la base de donn√©es depuis GitHub."
        )
        st.stop()

    return sqlite3.connect(db_path)

def ensure_database_structure():
    """V√©rifie et cr√©e la structure de la base de donn√©es."""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        try:
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS instructions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    year INTEGER,
                    week INTEGER,
                    title TEXT UNIQUE,
                    link TEXT,
                    pdf_link TEXT,
                    objet TEXT,
                    resume TEXT,
                    last_updated TIMESTAMP
                )
                """
            )
            conn.commit()

            # V√©rifier si la colonne last_updated existe
            cursor.execute("PRAGMA table_info(instructions)")
            columns = [column[1] for column in cursor.fetchall()]
            if "last_updated" not in columns:
                cursor.execute("ALTER TABLE instructions ADD COLUMN last_updated TIMESTAMP")
                conn.commit()

            return True
        except sqlite3.Error as e:
            st.error(f"‚ùå Erreur base de donn√©es: {e}")
            return False

def check_table_structure():
    """V√©rifie la structure actuelle de la table instructions."""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("PRAGMA table_info(instructions)")
        columns = cursor.fetchall()
        for column in columns:
            print(column)

def add_id_column_if_missing():
    """Ajoute la colonne 'id' si elle est manquante."""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        try:
            cursor.execute("ALTER TABLE instructions ADD COLUMN id INTEGER PRIMARY KEY AUTOINCREMENT")
            conn.commit()
            print("Colonne 'id' ajout√©e avec succ√®s.")
        except sqlite3.OperationalError as e:
            print(f"Erreur lors de l'ajout de la colonne 'id': {e}")

def recreate_table():
    """Recr√©e la table instructions avec la structure correcte."""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("DROP TABLE IF EXISTS instructions")
        cursor.execute(
            """
            CREATE TABLE instructions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                year INTEGER,
                week INTEGER,
                title TEXT UNIQUE,
                link TEXT,
                pdf_link TEXT,
                objet TEXT,
                resume TEXT,
                last_updated TIMESTAMP
            )
            """
        )
        conn.commit()
        print("Table 'instructions' recr√©√©e avec succ√®s.")

def load_data():
    """Charge les donn√©es depuis la base de donn√©es avec mise en cache."""

    # Utiliser le cache de Streamlit pour optimiser les performances
    @st.cache_data(ttl=300)  # Cache valide pendant 5 minutes
    def _load_data():
        with get_db_connection() as conn:
            query = "SELECT * FROM instructions"
            df = pd.read_sql_query(query, conn)
            return df

    try:
        return _load_data()
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement des donn√©es: {e}")
        return pd.DataFrame()

def get_instruction_details(title):
    """R√©cup√®re les d√©tails d'une instruction sp√©cifique."""
    with get_db_connection() as conn:
        query = "SELECT * FROM instructions WHERE title = ?"
        df = pd.read_sql_query(query, conn, params=(title,))
        if not df.empty:
            return df.iloc[0]
        return None

def add_instruction_to_db(year, week, title, link, pdf_link, objet, resume):
    """Ajoute ou met √† jour une instruction dans la base de donn√©es."""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        try:
            cursor.execute(
                """
                    INSERT OR REPLACE INTO instructions (year, week, title, link, pdf_link, objet, resume, last_updated)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (year, week, title, link, pdf_link, objet, resume, datetime.now()),
            )
            conn.commit()
            return True
        except sqlite3.Error as e:
            st.error(f"‚ùå Erreur DB insertion/mise √† jour: {e}")
            return False

# --- Fonctions de Web Scraping ---
def get_new_instructions(year, week):
    """R√©cup√®re les nouvelles instructions SDSSA pour une ann√©e et semaine donn√©es."""
    url = f"https://info.agriculture.gouv.fr/boagri/historique/annee-{year}/semaine-{week}"
    try:
        with st.spinner(f"R√©cup√©ration donn√©es ann√©e {year}, semaine {week}..."):
            response = requests.get(url, timeout=15)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, "html.parser")
                instructions = soup.find_all("a", href=True)
                sdssa_instructions = [a for a in instructions if "SDSSA" in a.text]
                new_instructions = []

                progress_bar = st.progress(0.0)
                for idx, instruction in enumerate(sdssa_instructions):
                    href = instruction["href"]
                    if not href.startswith(("http://", "https://")):
                        href = f"https://info.agriculture.gouv.fr{href}"
                    link = href
                    pdf_link = link.replace("/detail", "/telechargement")

                    try:
                        detail_response = requests.get(link, timeout=15)
                        if detail_response.status_code == 200:
                            soup = BeautifulSoup(
                                detail_response.content, "html.parser"
                            )
                            objet_tag = soup.find("b", text="OBJET : ")
                            objet = (
                                objet_tag.next_sibling.strip()
                                if objet_tag and objet_tag.next_sibling
                                else "OBJET : Inconnu"
                            )
                            resume_tag = soup.find("b", text="RESUME : ")
                            resume = (
                                resume_tag.next_sibling.strip()
                                if resume_tag and resume_tag.next_sibling
                                else "RESUME : Inconnu"
                            )
                            new_instructions.append(
                                (instruction.text, link, pdf_link, objet, resume)
                            )
                    except requests.RequestException as e:
                        st.warning(f"‚ö†Ô∏è Erreur d√©tails {link}: {e}")
                        new_instructions.append(
                            (
                                instruction.text,
                                link,
                                pdf_link,
                                "OBJET : Inconnu",
                                "RESUME : Inconnu",
                            )
                        )

                    # Mettre √† jour la barre de progression
                    progress_bar.progress((idx + 1) / len(sdssa_instructions))
                    # Pause pour √©viter de surcharger le serveur
                    time.sleep(0.5)

                return new_instructions
            else:
                st.warning(
                    f"‚ö†Ô∏è Impossible de r√©cup√©rer ann√©e {year} semaine {week} (Status: {response.status_code})"
                )
                return []
    except requests.RequestException as e:
        st.error(f"‚ùå Erreur connexion ann√©e {year} semaine {week}: {e}")
        return []

# --- Fonctions de Normalisation de Texte et Indexation Whoosh ---
@st.cache_resource
def create_whoosh_index(df):
    """Cr√©e ou ouvre l'index Whoosh."""
    analyzer = StemmingAnalyzer() | LowercaseFilter() | StopFilter()
    schema = Schema(
        title=TEXT(stored=True, analyzer=analyzer),
        objet=TEXT(stored=True, analyzer=analyzer),
        resume=TEXT(stored=True, analyzer=analyzer),
        content=TEXT(analyzer=analyzer),
    )
    index_dir = "indexdir"

    try:
        if not exists_in(index_dir) or len(os.listdir(index_dir)) == 0:
            ix = create_in(index_dir, schema)
            with st.spinner("Cr√©ation index Whoosh..."):
                writer = ix.writer()
                for index, row in df.iterrows():
                    writer.add_document(
                        title=row["title"],
                        objet=row["objet"],
                        resume=row["resume"],
                        content=f"{row['title']} {row['objet']} {row['resume']}",
                    )
                writer.commit()
        else:
            ix = open_dir(index_dir)

        return ix
    except LockError as e:
        st.error(f"‚ùå Erreur verrouillage index Whoosh: {e}")
        st.error("R√©essayez plus tard ou red√©marrez l'app.")
        st.stop()
        return None
    except Exception as e:
        st.error(f"‚ùå Erreur index Whoosh: {e}")
        st.error(traceback.format_exc())
        st.stop()
        return None

def update_whoosh_index(df):
    """Met √† jour l'index Whoosh avec les nouvelles donn√©es."""
    index_dir = "indexdir"
    if exists_in(index_dir):
        # Supprimer l'ancien index
        for f in os.listdir(index_dir):
            os.remove(os.path.join(index_dir, f))

    # Recr√©er l'index
    create_whoosh_index(df)

def get_synonyms(word):
    """R√©cup√®re les synonymes d'un mot."""
    synonyms = set()
    for syn in wordnet.synsets(word, lang="fra"):
        for lemma in syn.lemmas(lang="fra"):
            synonyms.add(lemma.name().lower())
    return synonyms

def normalize_text(text):
    """Normalise le texte."""
    lemmatizer = WordNetLemmatizer()
    words = word_tokenize(text.lower())
    normalized_words = [lemmatizer.lemmatize(word) for word in words]
    return " ".join(normalized_words)

# --- Fonction de recherche avanc√©e ---
def search_instructions(query, ix, data):
    """Effectue une recherche avanc√©e dans l'index Whoosh."""
    if not query or not ix:
        return data

    normalized_search = normalize_text(query)
    synonyms = set()
    for word in word_tokenize(normalized_search):
        synonyms.update(get_synonyms(word))

    # Ajouter les termes de recherche originaux
    synonyms.add(normalized_search)

    # Cr√©er une requ√™te combin√©e avec OR
    query_string = " OR ".join([f"content:{syn}" for syn in synonyms])

    try:
        with ix.searcher() as searcher:
            query_parser = QueryParser("content", ix.schema)
            parsed_query = query_parser.parse(query_string)
            results = searcher.search(parsed_query, limit=None)

            if len(results) > 0:
                filtered_data = pd.DataFrame(
                    [
                        {
                            "id": data.loc[data["title"] == hit["title"], "id"].values[
                                0
                            ]
                            if not data.loc[
                                data["title"] == hit["title"], "id"
                            ].empty
                            else None,
                            "year": data.loc[
                                data["title"] == hit["title"], "year"
                            ].values[0]
                            if not data.loc[
                                data["title"] == hit["title"], "year"
                            ].empty
                            else None,
                            "week": data.loc[
                                data["title"] == hit["title"], "week"
                            ].values[0]
                            if not data.loc[
                                data["title"] == hit["title"], "week"
                            ].empty
                            else None,
                            "title": hit["title"],
                            "link": data.loc[
                                data["title"] == hit["title"], "link"
                            ].values[0]
                            if not data.loc[
                                data["title"] == hit["title"], "link"
                            ].empty
                            else None,
                            "pdf_link": data.loc[
                                data["title"] == hit["title"], "pdf_link"
                            ].values[0]
                            if not data.loc[
                                data["title"] == hit["title"], "pdf_link"
                            ].empty
                            else None,
                            "objet": hit["objet"],
                            "resume": hit["resume"],
                            "last_updated": data.loc[
                                data["title"] == hit["title"], "last_updated"
                            ].values[0]
                            if not data.loc[
                                data["title"] == hit["title"], "last_updated"
                            ].empty
                            else None,
                            "score": hit.score,
                        }
                        for hit in results
                        if not data.loc[data["title"] == hit["title"]].empty
                    ]
                )

                # Trier par score de pertinence
                if not filtered_data.empty:
                    filtered_data = filtered_data.sort_values(
                        by="score", ascending=False
                    )

                return filtered_data
            else:
                return pd.DataFrame(columns=data.columns)
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la recherche: {e}")
        st.error(traceback.format_exc())
        return pd.DataFrame(columns=data.columns)

# --- Fonction pour mettre √† jour les donn√©es ---
def update_database(weeks_limit=10):
    """Met √† jour la base de donn√©es avec les nouvelles instructions."""
    db_path = "data/sdssa_instructions.db"
    if not os.path.exists(db_path):
        st.error(
            "‚ùå Base de donn√©es non trouv√©e! Veuillez d'abord t√©l√©charger la base de donn√©es."
        )
        return False

    with get_db_connection() as conn:
        cursor = conn.cursor()
        new_notes_added = False

        try:
            # R√©cup√©rer la date de la derni√®re mise √† jour
            cursor.execute("SELECT MAX(last_updated) FROM instructions")
            last_update_str = cursor.fetchone()[0]

            # D√©finir une date de d√©part par d√©faut (3 mois en arri√®re)
            default_start_date = datetime.now() - timedelta(days=90)

            if last_update_str:
                try:
                    last_update = datetime.strptime(
                        last_update_str, "%Y-%m-%d %H:%M:%S.%f"
                    )
                    # Si la derni√®re mise √† jour date de plus de 3 mois, utiliser 3 mois en arri√®re
                    if (datetime.now() - last_update).days > 90:
                        last_update = default_start_date
                except ValueError:
                    last_update = default_start_date
            else:
                # Aucune mise √† jour ant√©rieure trouv√©e, utiliser la date par d√©faut
                last_update = default_start_date

            # R√©cup√©rer l'ann√©e et la semaine actuelles
            current_date = datetime.now()
            current_year, current_week, _ = current_date.isocalendar()

            # R√©cup√©rer l'ann√©e et la semaine de la derni√®re mise √† jour
            start_year, start_week, _ = last_update.isocalendar()

            # Calculer la diff√©rence en semaines
            total_weeks_diff= (current_year - start_year) * 52 + (
                current_week - start_week
            )
            weeks_to_check = min(total_weeks_diff, weeks_limit)  # Limiter le nombre de semaines

            if weeks_to_check <= 0:
                st.info("‚úÖ La base de donn√©es est d√©j√† √† jour.")
                return False

            # Parcourir les semaines √† partir de la plus ancienne
            for week_offset in range(weeks_to_check):
                check_date = last_update + timedelta(weeks=week_offset)
                year, week, _ = check_date.isocalendar()
                st.info(f"V√©rification de l'ann√©e {year}, semaine {week}...")
                new_instructions = get_new_instructions(year, week)

                if new_instructions:
                    for instruction in new_instructions:
                        title, link, pdf_link, objet, resume = instruction
                        # V√©rifier si l'instruction existe d√©j√†
                        cursor.execute(
                            "SELECT id FROM instructions WHERE title = ?", (title,)
                        )
                        existing_instruction = cursor.fetchone()
                        if not existing_instruction:
                            # Ajouter √† la base de donn√©es
                            if add_instruction_to_db(
                                year, week, title, link, pdf_link, objet, resume
                            ):
                                new_notes_added = True
                                st.success(f"‚úÖ Ajout√©: {title}")
                        else:
                            #Mettre √† jour l'instruction existante
                            if add_instruction_to_db(
                                year, week, title, link, pdf_link, objet, resume
                            ):
                                st.info(f"‚úÖ Mis √† jour: {title}")
                    conn.commit()
                else:
                    st.info(f"Aucune nouvelle instruction pour l'ann√©e {year}, semaine {week}.")

            if new_notes_added:
                st.success("‚úÖ Mise √† jour de la base de donn√©es termin√©e.")
                return True
            else:
                st.info("‚úÖ Aucune nouvelle instruction trouv√©e.")
                return False

        except sqlite3.Error as e:
            st.error(f"‚ùå Erreur lors de la mise √† jour de la base de donn√©es: {e}")
            st.error(traceback.format_exc())
            return False
        except Exception as e:
            st.error(f"‚ùå Erreur inattendue: {e}")
            st.error(traceback.format_exc())
            return False

# --- Interface utilisateur Streamlit ---
def main():
    """Fonction principale pour l'application Streamlit."""
    st.markdown("<h1 class='main-header'>SDSSA Instructions</h1>", unsafe_allow_html=True)

    # --- Sidebar ---
    st.sidebar.markdown(
        "<h2 class='sub-header'>Options</h2>", unsafe_allow_html=True
    )

    # Option pour forcer la mise √† jour
    force_update = st.sidebar.checkbox("Forcer la mise √† jour", value=False)

    # S√©lecteur de fr√©quence de mise √† jour
    update_frequency = st.sidebar.selectbox(
        "Fr√©quence de mise √† jour",
        ["Hebdomadaire", "Mensuelle", "Trimestrielle"],
        index=["Hebdomadaire", "Mensuelle", "Trimestrielle"].index(
            st.session_state.update_frequency
        ),
    )
    st.session_state.update_frequency = update_frequency

    # Filtres par ann√©e et semaine
    available_years = (
        load_data()["year"].unique().tolist()
    )  # Charger les ann√©es disponibles depuis les donn√©es
    available_years.sort(reverse=True)  # Trier les ann√©es
    selected_year = st.sidebar.selectbox("Filtrer par ann√©e", [None] + available_years, index=0)
    available_weeks = (
        load_data()[load_data()["year"] == selected_year]["week"].unique().tolist()
        if selected_year
        else []
    )
    available_weeks.sort()
    selected_week = st.sidebar.selectbox("Filtrer par semaine", [None] + available_weeks, index=0)

    # --- Mise √† jour de la base de donn√©es ---
    if st.sidebar.button("Mettre √† jour la base de donn√©es"):
        if update_frequency == "Hebdomadaire":
            updated = update_database(weeks_limit=10)  # V√©rifier les 10 derni√®res semaines
        elif update_frequency == "Mensuelle":
            updated = update_database(
                weeks_limit=52
            )  # Approximation : 52 semaines pour 12 mois
        else:  # Trimestrielle
            updated = update_database(
                weeks_limit=156
            )  # Approximation : 156 semaines pour 3 ans
        if updated:
            st.session_state.is_db_updated = True  # Mettre √† jour l'√©tat
        else:
            st.session_state.is_db_updated = False
        #Recharger les donn√©es apr√®s la mise √† jour
        df = load_data()
        ix = create_whoosh_index(df)
    # T√©l√©chargement forc√© si demand√©
    if force_update:
        if download_db_from_github(force=True):
            st.session_state.is_db_updated = True
            df = load_data()
            ix = create_whoosh_index(df)
        else:
            st.session_state.is_db_updated = False

    # --- Chargement et affichage des donn√©es ---
    ensure_database_structure()
    df = load_data()

    # Cr√©er l'index Whoosh au d√©marrage de l'application ou apr√®s une mise √† jour
    if "whoosh_index" not in st.session_state or st.session_state.is_db_updated:
        ix = create_whoosh_index(df)
        st.session_state.whoosh_index = ix  # Stocker l'index dans la session
        st.session_state.is_db_updated = (
            False  # R√©initialiser le flag apr√®s la mise √† jour
        )
    else:
        ix = st.session_state.whoosh_index

    # --- Recherche ---
    st.markdown("<h2 class='sub-header'>Recherche</h2>", unsafe_allow_html=True)
    query = st.text_input("Rechercher des instructions (titre, objet, r√©sum√©)...")
    if st.button("Rechercher"):
        if not ix:
            st.error("‚ùå L'index de recherche n'est pas disponible.")
            st.stop()
        st.session_state.search_results = search_instructions(query, ix, df)
    # Afficher les r√©sultats de la recherche
    if query and st.session_state.search_results is not None:
        results_df = st.session_state.search_results
        if results_df.empty:
            st.info("Aucun r√©sultat trouv√© pour votre recherche.")
        else:
            st.write(f"R√©sultats de la recherche : {len(results_df)}")
            st.dataframe(
                results_df[
                    [
                        "year",
                        "week",
                        "title",
                        "objet",
                        "resume",
                        "link",
                        "pdf_link",
                        "last_updated",
                    ]
                ].style.set_properties(**{"text-align": "left"}),
                column_config={
                    "link": st.column_config.LinkColumn("Lien", display_text="Voir"),
                    "pdf_link": st.column_config.LinkColumn(
                        "PDF", display_text="T√©l√©charger"
                    ),
                    "last_updated": st.column_config.DatetimeColumn(
                        "Mis √† jour", format="DD/MM/YYYY HH:mm:ss"
                    ),
                },
                hide_index=True,
            )

    # --- Affichage des donn√©es ---
    st.markdown("<h2 class='sub-header'>Liste des instructions</h2>", unsafe_allow_html=True)
    # Filtrer les donn√©es par ann√©e et semaine si des filtres sont s√©lectionn√©s
    filtered_df = df.copy()
    if selected_year:
        filtered_df = filtered_df[filtered_df["year"] == selected_year]
    if selected_week:
        filtered_df = filtered_df[filtered_df["week"] == selected_week]

    if not filtered_df.empty:
        st.dataframe(
            filtered_df[
                [
                    "year",
                    "week",
                    "title",
                    "objet",
                    "resume",
                    "link",
                    "pdf_link",
                    "last_updated",
                ]
            ].sort_values(by=["year", "week"], ascending=False).style.set_properties(
                **{"text-align": "left"}
            ),
            column_config={
                "link": st.column_config.LinkColumn("Lien", display_text="Voir"),
                "pdf_link": st.column_config.LinkColumn(
                    "PDF", display_text="T√©l√©charger"
                ),
                "last_updated": st.column_config.DatetimeColumn(
                    "Mis √† jour", format="DD/MM/YYYY HH:mm:ss"
                ),
            },
            hide_index=True,
        )
    else:
        st.info("Aucune instruction √† afficher avec les filtres s√©lectionn√©s.")

    # --- D√©tails de l'instruction s√©lectionn√©e ---
    st.markdown("<h2 class='sub-header'>D√©tails de l'instruction</h2>", unsafe_allow_html=True)
    selected_title = st.selectbox(
        "S√©lectionner une instruction pour voir les d√©tails", [""] + df["title"].tolist()
    )
    if selected_title:
        instruction_details = get_instruction_details(selected_title)
        if instruction_details:
            st.write(
                f"""
                <div class="card">
                    <p><strong>Ann√©e:</strong> {instruction_details['year']}</p>
                    <p><strong>Semaine:</strong> {instruction_details['week']}</p>
                    <p><strong>Titre:</strong> {instruction_details['title']}</p>
                    <p><strong>Objet:</strong> {instruction_details['objet']}</p>
                    <p><strong>R√©sum√©:</strong> {instruction_details['resume']}</p>
                    <p><strong>Lien:</strong> <a href="{instruction_details['link']}" target="_blank">Voir l'instruction</a></p>
                    <p><strong>Lien PDF:</strong> <a href="{instruction_details['pdf_link']}" target="_blank">T√©l√©charger le PDF</a></p>
                    <p><strong>Derni√®re mise √† jour:</strong> {instruction_details['last_updated']}</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
        else:
            st.error("Instruction non trouv√©e.")

    # --- Footer ---
    st.markdown(
        """
<div class="footer">
    <p>¬© 2024 SDSSA Instructions. Tous droits r√©serv√©s.</p>
    <p>Application d√©velopp√©e par [Votre Nom/Entreprise].</p>
</div>
""",
        unsafe_allow_html=True,
    )

if __name__ == "__main__":
    main()
